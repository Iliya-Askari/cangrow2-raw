{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4db9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51053a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb07a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume = pd.read_csv('../DataSet/Role-Resume-Dataset.csv')\n",
    "df_jobs = pd.read_csv('../DataSet/Job-Description-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f4f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cf3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270d62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe41001",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68941120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694b1a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db04acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0cfe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11675b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5570067",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c8ce01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume['job_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47a52d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['Job Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd9638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume['clean_resume'] = df_resume['resume'].str.lower()\n",
    "df_resume['clean_resume'] = df_resume['clean_resume'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4112e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "df_resume['clean_resume'] = df_resume['clean_resume'].apply(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a849b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "# استفاده از stopwords آماده sklearn\n",
    "stop_words = set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "# # افزودن کلمات پرت و نویز که باید حذف شوند\n",
    "# custom_stopwords = {'like', 'using', 'etc', 'must', 'should', 'will', 'can', 'want', 'get', 'make'}\n",
    "# stop_words.update(custom_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209afe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_resume['clean_resume'] = df_resume['clean_resume'].apply(lambda tokens: [word for word in tokens if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume['clean_resume'] = df_resume['clean_resume'].apply(lambda tokens: ' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2771ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resume_clean = df_resume.drop(columns='resume')\n",
    "df_resume_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf10a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jobs['clean_description'] = df_jobs['Job Description'].str.lower()\n",
    "df_jobs['clean_description'] = df_jobs['clean_description'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', ' ', str(x)))\n",
    "df_jobs['clean_description'] = df_jobs['clean_description'].apply(tokenizer.tokenize)\n",
    "df_jobs['clean_description'] = df_jobs['clean_description'].apply(lambda tokens: [word for word in tokens if word not in stop_words])\n",
    "df_jobs['clean_description'] = df_jobs['clean_description'].apply(lambda tokens: ' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b962cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_resume_clean['clean_resume']\n",
    "y = df_resume_clean['job_title']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_vect = vectorizer.fit_transform(X)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vect, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "df_resume['job_title'].value_counts().plot(kind='bar', color='skyblue')\n",
    "plt.title('Distribution of Job Titles in Resumes')\n",
    "plt.xlabel('Job Title')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48f01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Model accuracy : \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification report : \", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4db552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_keywords(texts, top_n=30):\n",
    "    tfidf = TfidfVectorizer(max_features=5000)\n",
    "    tfidf_matrix = tfidf.fit_transform(texts)\n",
    "    scores = np.asarray(tfidf_matrix.sum(axis=0)).ravel()\n",
    "    words = tfidf.get_feature_names_out()\n",
    "    top_idx = scores.argsort()[::-1][:top_n]\n",
    "    return [words[i] for i in top_idx]\n",
    "\n",
    "\n",
    "def predict_job_and_missing_skills_v2(resume_text):\n",
    "    cleaned = resume_text.lower()\n",
    "    cleaned = re.sub(r'[^a-zA-Z\\s]', ' ', cleaned)\n",
    "    tokens = tokenizer.tokenize(cleaned)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    \n",
    "    vect = vectorizer.transform([cleaned_text])\n",
    "    pred_label = model.predict(vect)[0]\n",
    "    job_title = label_encoder.inverse_transform([pred_label])[0]\n",
    "\n",
    "    job_descs = df_jobs[df_jobs['Job Title'].str.lower().str.contains(job_title.lower())]\n",
    "    if job_descs.empty:\n",
    "        return job_title, []\n",
    "\n",
    "    top_keywords = get_top_keywords(job_descs['clean_description'], top_n=50)\n",
    "    resume_words = set(tokens)\n",
    "    missing_skills = [word for word in top_keywords if word not in resume_words]\n",
    "    return job_title, missing_skills[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bundle = {\n",
    "    'model': model,\n",
    "    'vectorizer': vectorizer,\n",
    "    'label_encoder': label_encoder,\n",
    "    'stop_words': stop_words,\n",
    "    'tokenizer': tokenizer,\n",
    "    'df_jobs': df_jobs\n",
    "}\n",
    "\n",
    "joblib.dump(model_bundle, '../Model/model_resume.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55ca873",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_input = \"\"\"\n",
    "Sara Ahmadi  \n",
    "Vanak St., Tehran, Iran | +989123456789 | sara.ahmadi.dev@gmail.com | github.com/saraahmadi | linkedin.com/in/saraahmadi\n",
    "\n",
    "About Me  \n",
    "Creative and detail-oriented Web Developer with 3+ years of experience designing, developing, and managing responsive websites and web applications. Skilled in front-end and back-end technologies, with a passion for clean code and user-focused design.\n",
    "\n",
    "Experience  \n",
    "Front-End Developer | Tapsell Technologies | Jul 2021 – Present  \n",
    "- Developed and maintained responsive websites using React.js, Tailwind CSS, and TypeScript.  \n",
    "- Improved load times by 30% through performance optimization and lazy loading techniques.  \n",
    "- Collaborated with UI/UX designers and back-end developers to implement interactive features.\n",
    "\n",
    "Web Developer Intern | CafeBazaar | Jan 2020 – Jun 2021  \n",
    "- Assisted in developing internal tools using Node.js and Express.  \n",
    "- Contributed to the migration of legacy code to modern JavaScript standards.  \n",
    "- Created reusable React components to speed up future development.\n",
    "\n",
    "Education  \n",
    "B.Sc. in Computer Engineering | Sharif University of Technology | 2016 – 2020\n",
    "\n",
    "Skills  \n",
    "- Front-End: HTML5, CSS3, JavaScript (ES6+), React, Tailwind CSS, Next.js  \n",
    "- Back-End: Node.js, Express.js, MongoDB  \n",
    "- Tools: Git, Webpack, Figma, VS Code  \n",
    "- Testing: Jest, Cypress  \n",
    "- Deployment: Vercel, Netlify\n",
    "\n",
    "Projects  \n",
    "- Personal Portfolio: Designed and deployed a mobile-friendly developer portfolio using Next.js and Tailwind.  \n",
    "- Task Manager App: A full-stack to-do app with authentication and CRUD features (MERN stack).\n",
    "\n",
    "Languages  \n",
    "Persian (Native), English (Professional)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "predicted_job, suggested_skills = predict_job_and_missing_skills_v2(resume_input)\n",
    "\n",
    "print(\"Suggested job :\", predicted_job)\n",
    "print(\"Suggested skills to learn:\")\n",
    "print(suggested_skills)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
